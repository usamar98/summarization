{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textsummarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc8nB2oBFduQ",
        "outputId": "cd970c2e-2729-4217-a346-2012a47ad7ed"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1FHeHJRxOYT",
        "outputId": "78ad7073-e349-40d2-ac5d-9a98c621edb2"
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olR_2Pr6F_XK",
        "outputId": "97319ec9-a10d-4e6c-98c2-2ad14930559f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "from attention import AttentionLayer\n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "fPUwCPqpGtWh",
        "outputId": "dd522453-0c06-46c0-eacf-22856d4a9f1e"
      },
      "source": [
        "reviews = pd.read_csv(\"Book.csv\")\n",
        "print(reviews.shape)\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A few months ago I had the opportunity to complete Andrew Ngs Machine Learning MOOC taught on Coursera It serves as a very good introduction for anyone who wants to venture into the world of AI ML But the catch this course is taught in Octave I always wondered how amazing this course could be if it were in Python I finally decided to re-take the course but only this time I would be completing the programming assignments in Python In these series of blog posts I plan to write about the Python version of the programming exercises used in the course Im doing this for a few reasons It will help anyone who wanted a Python version of the course that includes me as well It will hopefully benefit R users who are willing to learn about the Pythonic implementation of the algorithms they are already familiar with Pre-requisites Its highly reommended that first you watch the week 1 video lectures Should have basic familiarity with the Python ecosystem In this section we will look at the simplest Machine Learning algorithms First some context on the problem statement Here we will implement linear regrssion with one variable to predict profits for a food tuck Suppose you are the CEO of a restaurant franchise ad are considering different cities for opening a new outlet The chain already has trucks in various cities and you have data for profits and populations from the cities The file ex1data txt available under week 2s assignment material contains the dataset for our linear regression exercise The first column is the population of a city and the second column is the profit of a food truck ithat city A negative value for profit indicates a loss</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text\n",
              "0  A few months ago I had the opportunity to complete Andrew Ngs Machine Learning MOOC taught on Coursera It serves as a very good introduction for anyone who wants to venture into the world of AI ML But the catch this course is taught in Octave I always wondered how amazing this course could be if it were in Python I finally decided to re-take the course but only this time I would be completing the programming assignments in Python In these series of blog posts I plan to write about the Python version of the programming exercises used in the course Im doing this for a few reasons It will help anyone who wanted a Python version of the course that includes me as well It will hopefully benefit R users who are willing to learn about the Pythonic implementation of the algorithms they are already familiar with Pre-requisites Its highly reommended that first you watch the week 1 video lectures Should have basic familiarity with the Python ecosystem In this section we will look at the simplest Machine Learning algorithms First some context on the problem statement Here we will implement linear regrssion with one variable to predict profits for a food tuck Suppose you are the CEO of a restaurant franchise ad are considering different cities for opening a new outlet The chain already has trucks in various cities and you have data for profits and populations from the cities The file ex1data txt available under week 2s assignment material contains the dataset for our linear regression exercise The first column is the population of a city and the second column is the profit of a food truck ithat city A negative value for profit indicates a loss"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3W5XT37HNIj",
        "outputId": "1954c1d0-e057-4430-82db-c99eb5485342"
      },
      "source": [
        "# Check for any nulls values\n",
        "reviews.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr22uSGbHY7O",
        "outputId": "ac16b01f-3ed2-418c-9179-75f98dd187e2"
      },
      "source": [
        "# let's inspect some reviews\n",
        "for i in range(1):\n",
        "    print(\"Review: \",i)\n",
        "    print(reviews.text)\n",
        "    print('-'*80)\n",
        "    print(reviews.text)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review:  0\n",
            "0    A few months ago I had the opportunity to complete Andrew Ngs Machine Learning MOOC taught on Coursera It serves as a very good introduction for anyone who wants to venture into the world of AI ML But the catch this course is taught in Octave I always wondered how amazing this course could be if it were in Python I finally decided to re-take the course but only this time I would be completing the programming assignments in Python In these series of blog posts I plan to write about the Python version of the programming exercises used in the course Im doing this for a few reasons It will help anyone who wanted a Python version of the course that includes me as well It will hopefully benefit R users who are willing to learn about the Pythonic implementation of the algorithms they are already familiar with Pre-requisites Its highly reommended that first you watch the week 1 video lectures Should have basic familiarity with the Python ecosystem In this section we will look at the simplest Machine Learning algorithms First some context on the problem statement Here we will implement linear regrssion with one variable to predict profits for a food tuck Suppose you are the CEO of a restaurant franchise ad are considering different cities for opening a new outlet The chain already has trucks in various cities and you have data for profits and populations from the cities The file ex1data txt available under week 2s assignment material contains the dataset for our linear regression exercise The first column is the population of a city and the second column is the profit of a food truck ithat city A negative value for profit indicates a loss\n",
            "Name: text, dtype: object\n",
            "--------------------------------------------------------------------------------\n",
            "0    A few months ago I had the opportunity to complete Andrew Ngs Machine Learning MOOC taught on Coursera It serves as a very good introduction for anyone who wants to venture into the world of AI ML But the catch this course is taught in Octave I always wondered how amazing this course could be if it were in Python I finally decided to re-take the course but only this time I would be completing the programming assignments in Python In these series of blog posts I plan to write about the Python version of the programming exercises used in the course Im doing this for a few reasons It will help anyone who wanted a Python version of the course that includes me as well It will hopefully benefit R users who are willing to learn about the Pythonic implementation of the algorithms they are already familiar with Pre-requisites Its highly reommended that first you watch the week 1 video lectures Should have basic familiarity with the Python ecosystem In this section we will look at the simplest Machine Learning algorithms First some context on the problem statement Here we will implement linear regrssion with one variable to predict profits for a food tuck Suppose you are the CEO of a restaurant franchise ad are considering different cities for opening a new outlet The chain already has trucks in various cities and you have data for profits and populations from the cities The file ex1data txt available under week 2s assignment material contains the dataset for our linear regression exercise The first column is the population of a city and the second column is the profit of a food truck ithat city A negative value for profit indicates a loss\n",
            "Name: text, dtype: object\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKpwKAItT85E",
        "outputId": "637489e8-b97b-40e6-f9cd-ab58035f6cba"
      },
      "source": [
        "\n",
        "cleaned_text = []\n",
        "for text in reviews['text']:\n",
        "    cleaned_text.append(text)\n",
        "print(\"Texts are complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts are complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9uDltz5T9UR",
        "outputId": "c025c3b6-54a6-490e-ca3c-2441262a68fb"
      },
      "source": [
        "# let's inspect some clean reviews\n",
        "for i in range(1):\n",
        "    print(\"Review: \",i+1)\n",
        "    print('-'*1)\n",
        "    print(cleaned_text[i])\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review:  1\n",
            "-\n",
            "A few months ago I had the opportunity to complete Andrew Ngs Machine Learning MOOC taught on Coursera It serves as a very good introduction for anyone who wants to venture into the world of AI ML But the catch this course is taught in Octave I always wondered how amazing this course could be if it were in Python I finally decided to re-take the course but only this time I would be completing the programming assignments in Python In these series of blog posts I plan to write about the Python version of the programming exercises used in the course Im doing this for a few reasons It will help anyone who wanted a Python version of the course that includes me as well It will hopefully benefit R users who are willing to learn about the Pythonic implementation of the algorithms they are already familiar with Pre-requisites Its highly reommended that first you watch the week 1 video lectures Should have basic familiarity with the Python ecosystem In this section we will look at the simplest Machine Learning algorithms First some context on the problem statement Here we will implement linear regrssion with one variable to predict profits for a food tuck Suppose you are the CEO of a restaurant franchise ad are considering different cities for opening a new outlet The chain already has trucks in various cities and you have data for profits and populations from the cities The file ex1data txt available under week 2s assignment material contains the dataset for our linear regression exercise The first column is the population of a city and the second column is the profit of a food truck ithat city A negative value for profit indicates a loss\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "abUFjOdOULtx",
        "outputId": "cfcfad26-8d5a-4cc3-cf19-38c1b51a5a2f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "\n",
        "\n",
        "for i in cleaned_text:\n",
        "    text_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text': text_word_count})\n",
        "length_df.hist(bins=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THrLrhTZVd74",
        "outputId": "75c8d607-5309-4a03-bbb4-adb0351e4a7b"
      },
      "source": [
        "count = 0\n",
        "for i in cleaned_text:\n",
        "    if(len(i.split())<=50):\n",
        "        count += 1\n",
        "print(count/len(cleaned_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Yy_os_HBir9o",
        "outputId": "b5c77d09-7c98-4ddf-f1d1-84be03efba27"
      },
      "source": [
        "max_text_len=50\n",
        "\n",
        "cleaned_text = np.array(cleaned_text)\n",
        "\n",
        "short_text=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    \n",
        "    if (len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        \n",
        "\n",
        "df=pd.DataFrame({'text':short_text})\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-a2a80374e78e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2176\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1861\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1862\u001b[0m         )\n\u001b[1;32m   1863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "5jHJ7piKhoG4",
        "outputId": "db7978bb-1543-48ad-b8b1-96fc1c90d8b0"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "x_voc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-05f519d73e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#prepare a tokenizer for reviews on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_tr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "S7Q0ULXjhK6u",
        "outputId": "fe69c65d-984c-4d1f-f83b-34d48bea9b03"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 320\n",
        "embedding_dim=220\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0.2)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.3,recurrent_dropout=0.1)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-91506d1bf6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeejxL9RhLK_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdpHcD3FhLYo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czudoI2HhLtZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}